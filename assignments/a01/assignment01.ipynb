{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a72e5cb4",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\" >\n",
    "<h1 style=\"margin-top: 0.2em; margin-bottom: 0.1em;\">Assignment 1</h1>\n",
    "<h4 style=\"margin-top: 0.7em; margin-bottom: 0.3em; font-style:italic\">\n",
    "Commit your solutions to our \n",
    "<a href=''>GitHub Classroom TBA</a>\n",
    "until May 1, 23:59</h4>\n",
    "</div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252b0fe0",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "## Correlation of Future Orientation Index and Gross Domestic Product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82d402b",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "In this exercise, we try to reproduce the findings of the article “Quantifying the Advantage of Looking Forward” http://www.nature.com/articles/srep00350.\n",
    "\n",
    "According to the study, the GDP per capita of countries is positively correlated to how much their population searches in Google for the next year, relative to how much they search for the previous year.\n",
    "\n",
    "This ratio is called the Future Orientation Index (FOI). So for example for the year 2017 the FOI can be calculated as: FOI = number of searches for the term “2018” / number of searches for the term “2016”.\n",
    "\n",
    "You will do the following tasks:\n",
    "1. Aquire World Bank Data\n",
    "2. Calculate the Future Orientation Index in Google Trends\n",
    "3. Test the correlation between GDP and FOI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e59b4b",
   "metadata": {},
   "source": [
    "### Install requirements\n",
    "\n",
    "The following cell contains all the necessary dependencies needed for this task. If you run the cell everything will be installed.  \n",
    "* [`wbgapi`](https://github.com/tgherzog/wbgapi) is a Python package which provides modern, pythonic access to the World Bank's data API. [Here](https://github.com/tgherzog/wbgapi) is the documentation of `wbgapi`.\n",
    "* [`pandas`](https://pandas.pydata.org/docs/index.html) is a Python package for creating and working with tabular data. [Here](https://pandas.pydata.org/docs/reference/index.html) is the documentation of `pandas`.\n",
    "* [`matplotlib`](https://matplotlib.org/) is a Python package for creating plots. [Here](https://matplotlib.org/stable/api/index.html) is the documentation of `matplotlib`.\n",
    "* [`scipy`](https://scipy.org/) is a Python package with different algorithms for scientific computing. [Here](https://docs.scipy.org/doc/scipy/reference/index.html#scipy-api) is the documentation of `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b72588",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install wbgapi\n",
    "! pip install pandas\n",
    "! pip install matplotlib\n",
    "! pip install scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b6e3f8",
   "metadata": {},
   "source": [
    "### Exercise 1: World Bank Data *(3 points)*\n",
    "#### 1.1 Download WDI data\n",
    "\n",
    "From the WDI we need three indicators:\n",
    "* Gross Domestic Product (GDP) per capita corrected by the Purchase Power Parity (PPP in current or 2005 international $, `\"NY.GDP.PCAP.PP.KD\"`)\n",
    "* The amount of Internet users (per 100 people, `\"IT.NET.USER.ZS\"`\n",
    "* The total population (described as as \"Population, Total\", `\"SP.POP.TOTL\"`)\n",
    "\n",
    "In the following code chunk, download all data (including extras) for all countries in year 2014 and save it as a pandas data frame. See [here](https://github.com/tgherzog/wbgapi#accessing-data) how to use the `data` subpackage of `wbgapi`.\n",
    "\n",
    "Hint: To remove aggregates (economic regions defined by the World Bank) and include only countries, use `skipAggs=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c9b324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e35e271",
   "metadata": {},
   "source": [
    "Now drop any row that has `NaN` for this you can use `pandas` [`dropna`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b5278e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4854dd95",
   "metadata": {},
   "source": [
    "Next only keep rows where there are at least 5 Million internet users. Keep in Mind that the Internet Users are per 100 people, so don't forget to take the population into account.\n",
    "\n",
    "For example in the dataset Austria has 80.995825 internet users per 100 people, while 8546356 people living in Austria. This means Austria has 6922191.55 internet users in total. The calculation for that is as follows:\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "internet\\_users = population \\cdot \\frac{internet\\_user\\_per\\_100}{100}\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffe01e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4f8562a",
   "metadata": {},
   "source": [
    "### Exercise 2: The Future Orientation Index in Google Trends *(3 points)*\n",
    "#### 2.1 Download data from Google Trends\n",
    "\n",
    "You can download the data from Google Trends following these steps:\n",
    "\n",
    "1) Log out from your google account or set its language to English\n",
    "\n",
    "2) Go to trends.google.com and search for 2013 \n",
    "\n",
    "3) Add 2015 as a search term\n",
    "\n",
    "4) Select custom time rage: full year: 2014\n",
    "\n",
    "5) Set the region to “Worldwide”. You can also try with this link (it links to the google trends page with all settings from above applied): https://trends.google.com/trends/explore?date=2014-01-01%202014-12-31&q=2013,2015\n",
    "\n",
    "6) Go to the map at “Compared breakdown by region” and tick on “include low search volume regions”\n",
    "\n",
    "7) On the top right menu click the download button to get a geoMap.csv file\n",
    "\n",
    "Load the .csv file in a pandas data frame. Notice in the file the first 3 Lines are actually only information (while the third is the header). You can skip these lines by using `skiprows=3` in `pd.read_csv`. Set the headers to `\"Country\", \"G2013\", \"G2015\"`, this can be done by the keyword argument `names` in `pd.read_csv`.\n",
    "\n",
    "Now remove again all rows containing `NaN`.\n",
    "\n",
    "All the percentage data is saved as a string containing the `%` symbol. You can remove this with `pandas` [`str.replace`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.replace.html) method and save them as integer with `pandas` [`astype`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html) method. Do this for column `G2013` and `G2015`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d49e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2afa666c",
   "metadata": {},
   "source": [
    "#### 2.2 Calculate the Future Orientation Index\n",
    "\n",
    "In the following code chunk, make a new column in the Google Trends dataframe with the Future Orientation Index, which is the ratio between the search volume for 2015 and 2013 in 2014 for each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5441e4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3322c9c",
   "metadata": {},
   "source": [
    "#### 2.3 Merge with World Bank data\n",
    "\n",
    "Merge the WDI and google trends data frames, using the name of the country. For this you can use `pandas` [`merge`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67058308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcc137f0",
   "metadata": {},
   "source": [
    "### Exercise: 3 Testing the correlation between GDP and FOI *(2 points)*\n",
    "#### 3.1 Visualize FOI vs GDP\n",
    "\n",
    "Now that you have the FOI index, GPD per capita and PPP value for each country, you can make a scatter plot of FOI vs GDP.\n",
    "\n",
    "For this you can use the [`scatter`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html) method of `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fdd05e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f404be5",
   "metadata": {},
   "source": [
    "#### 3.2 Measure Pearson’s correlation\n",
    "\n",
    "In the following chunk, calculate Pearson’s correlation coefficient between GDP and FOI.\n",
    "\n",
    "For this you can use the [`pearsonr`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html) method of `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18b0a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "657dc825",
   "metadata": {},
   "source": [
    "### To learn more\n",
    "#### Check robustness\n",
    "* What result do you get if you use other years? What if you choose one of the earliest years in Google trends?\n",
    "* How do results change if you use a different threshod instead of 5 Million Internet users?\n",
    "    \n",
    "#### Test other hypotheses\n",
    "* Is future orientation generating wealth? Or is wealth enabling to look more to the future?\n",
    "* Is the FOI really measuring orientation to the future? Could it be something else?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe67d1f",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "## Using Google Trends data to model Flu Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b307d8a0",
   "metadata": {},
   "source": [
    "### Install requirements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98ada14",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U pytrends\n",
    "! pip install requests\n",
    "! pip install statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6323cb",
   "metadata": {},
   "source": [
    "### Exercise 4 *(4 points)*\n",
    "Use the [pytrends module](https://pypi.org/project/pytrends/) to get weekly Google Trends data concerning the [Flu/Influenza](https://en.wikipedia.org/wiki/Influenza) virus from the beginning of 2014 until the end of 2018. \n",
    "<br>\n",
    "\n",
    "- Create an instance of the `TrendReq` class\n",
    "- Find the appropriate query term. The TrendReq class includes a method `suggestions`, which should help you in this task (the query term can look like e.g. `/m/03x_m3v`).\n",
    "- Specify the correct geographical region, the timeframe, and the key-word list. Use the `build_payload` method to store this information for future requests.\n",
    "- Use the `interest_over_time` method to get the data.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e196189c",
   "metadata": {},
   "source": [
    "***Hint:*** *the pytrends module currently has a bug. If you get a `TooManyRequestsError` despite following the documentation, try following the advice outlined [here](https://github.com/GeneralMills/pytrends/issues/573#issuecomment-1501897119) or [here](https://github.com/GeneralMills/pytrends/issues/561#issuecomment-1462899426) (both solve the issue).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c970856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fc1dc8e",
   "metadata": {},
   "source": [
    "### Exercise 5 *(2 points)*\n",
    "\n",
    "In the `a01` folder you will find a file named `ILINet.csv`, which contains data regarding the occurance of Influenza like Illnesses in the US. You can also find the data and the corresponding [documentation](https://gis.cdc.gov/grasp/fluview/FluViewPhase2QuickReferenceGuide.pdf) on the CDC's [FluView interactive dashboard](https://gis.cdc.gov/grasp/fluview/fluportaldashboard.html).\n",
    "<br>\n",
    "- Read the csv file, and store it as a [pandas](https://pypi.org/project/pandas/) dataframe. You might need to use the `skiprows` argument of the `read_csv` method to be able to load the data correctly.\n",
    "- Select the columns named `YEAR`, `WEEK`, and `% WEIGHTED ILI` which will be needed for our analysis. Additionally, drop the rows which store observations from before 2014, or after 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9ccc2b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e08a2ca",
   "metadata": {},
   "source": [
    "### Exercise 6 *(6 points)*\n",
    "\n",
    "Next, we will use the [statsmodels](https://www.statsmodels.org/stable/index.html) module to build some models which can predict Flu infections. \n",
    "<br>\n",
    "- Create an [autoregressive model](https://www.statsmodels.org/dev/generated/statsmodels.tsa.ar_model.AutoReg.html) using `% WEIGHTED ILI` as a dependent variable and it's [lagged](https://ibf.org/knowledge/glossary/lagged-dependent-variable-156) versions as explanatory variables. You are free to use as many lags as possible to find the best fitting model, as measured by the [Bayesian Information Criterion (BIC)](https://en.wikipedia.org/wiki/Bayesian_information_criterion).\n",
    "- You may also add [trend](https://towardsdatascience.com/understanding-time-series-trend-addfd9d7764e) and/or [seasonal](https://towardsdatascience.com/seasonality-of-time-series-5b45b4809acd) variables to the model to improve your model's fit.\n",
    "- Create another model with `% WEIGHTED ILI` as a dependent variable and the Google Trend volume from the same week as the explanatory variable.\n",
    "- Last, create a model which uses both the lagged values of `% WEIGHTED ILI` and the Google Trends data (and/or its lagged versions) as explanatory variables to achieve the best fit. \n",
    "- Create a linechart showing the real values of `% WEIGHTED ILI` as well as the values predicted by all three models. Discuss your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "62d1e565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63c881d5",
   "metadata": {},
   "source": [
    "### To learn more\n",
    "#### p-Hacking\n",
    "* Try downloading data for other queries to see if you can improve the fit of your model.\n",
    "    \n",
    "#### Prediction\n",
    "* Download the Google Trends data for 2019, and use your models to predict the values of `% WEIGHTED ILI`. Do the models make good predictions? Which model performs better?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
